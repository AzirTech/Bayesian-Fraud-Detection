{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Author__ = \"Chen Zhang\"\n",
    "from DataPreprocessing import DataInit, LGBM_FeatureSelection as FS\n",
    "#package I wrote, containg initialization of datas, feature selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from blitz.modules import BayesianLinear\n",
    "from blitz.utils import variational_estimator\n",
    "\n",
    "import torch\n",
    "import torch.utils as utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans = pd.read_csv(r'..\\data\\train_transaction_new.csv', index_col='TransactionID')\n",
    "train_id = pd.read_csv(r'..\\data\\train_identity_new.csv', index_col='TransactionID')\n",
    "\n",
    "test_trans = pd.read_csv(r'..\\data\\test_transaction_new_nolabel.csv', index_col='TransactionID')\n",
    "test_id = pd.read_csv(r'..\\data\\test_identity_new.csv', index_col='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = train_trans.merge(test_id, how='left', left_index=True, right_index=True)\n",
    "target_raw = test_trans.merge(test_id, how='left', left_index=True, right_index=True)\n",
    "target_raw.insert(loc=0,column='isFraud',value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_cat_data_list = [3,4,5,6,7,8,9,10,11,14,15] + list(range(45,54))\n",
    "data_cat_data_list = transaction_cat_data_list + list(range(392+12,392+41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataInit(train_raw, target_raw, data_cat_data_list, dropping_list=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3379840</th>\n",
       "      <td>-0.437961</td>\n",
       "      <td>-2.273059</td>\n",
       "      <td>-1.595233</td>\n",
       "      <td>0.308872</td>\n",
       "      <td>2.414377</td>\n",
       "      <td>0.643344</td>\n",
       "      <td>-2.256241</td>\n",
       "      <td>-1.679215</td>\n",
       "      <td>-1.546406</td>\n",
       "      <td>-2.835276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415851</th>\n",
       "      <td>-0.365802</td>\n",
       "      <td>-0.863972</td>\n",
       "      <td>0.037220</td>\n",
       "      <td>1.408793</td>\n",
       "      <td>-0.202174</td>\n",
       "      <td>0.643344</td>\n",
       "      <td>0.661603</td>\n",
       "      <td>-1.679215</td>\n",
       "      <td>0.586847</td>\n",
       "      <td>0.356219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269438</th>\n",
       "      <td>0.386127</td>\n",
       "      <td>0.545114</td>\n",
       "      <td>-1.478316</td>\n",
       "      <td>0.019750</td>\n",
       "      <td>-0.202174</td>\n",
       "      <td>0.643344</td>\n",
       "      <td>0.661603</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>-1.325725</td>\n",
       "      <td>0.356219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3554694</th>\n",
       "      <td>-0.486700</td>\n",
       "      <td>-2.273059</td>\n",
       "      <td>-0.421679</td>\n",
       "      <td>-0.967037</td>\n",
       "      <td>2.414377</td>\n",
       "      <td>0.643344</td>\n",
       "      <td>-1.385243</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>-1.546406</td>\n",
       "      <td>-2.835276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994660</th>\n",
       "      <td>-0.468551</td>\n",
       "      <td>0.545114</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.013464</td>\n",
       "      <td>-0.202174</td>\n",
       "      <td>-0.973861</td>\n",
       "      <td>-1.864292</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>-0.712721</td>\n",
       "      <td>0.356219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998035</th>\n",
       "      <td>0.151149</td>\n",
       "      <td>0.545114</td>\n",
       "      <td>0.674417</td>\n",
       "      <td>1.220235</td>\n",
       "      <td>-0.202174</td>\n",
       "      <td>0.643344</td>\n",
       "      <td>0.661603</td>\n",
       "      <td>-1.679215</td>\n",
       "      <td>-1.350245</td>\n",
       "      <td>0.356219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158790</th>\n",
       "      <td>-0.455520</td>\n",
       "      <td>0.545114</td>\n",
       "      <td>-0.912731</td>\n",
       "      <td>1.408793</td>\n",
       "      <td>-0.202174</td>\n",
       "      <td>0.643344</td>\n",
       "      <td>0.661603</td>\n",
       "      <td>-1.679215</td>\n",
       "      <td>-0.516560</td>\n",
       "      <td>0.356219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278176</th>\n",
       "      <td>-0.327351</td>\n",
       "      <td>0.545114</td>\n",
       "      <td>-0.738329</td>\n",
       "      <td>1.188809</td>\n",
       "      <td>-0.202174</td>\n",
       "      <td>0.643344</td>\n",
       "      <td>0.661603</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>1.494093</td>\n",
       "      <td>0.356219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516397</th>\n",
       "      <td>-0.465684</td>\n",
       "      <td>-2.273059</td>\n",
       "      <td>-0.916628</td>\n",
       "      <td>0.107743</td>\n",
       "      <td>2.414377</td>\n",
       "      <td>-0.973861</td>\n",
       "      <td>0.574503</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>-1.546406</td>\n",
       "      <td>-2.835276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385240</th>\n",
       "      <td>-0.381169</td>\n",
       "      <td>-2.273059</td>\n",
       "      <td>-0.916628</td>\n",
       "      <td>0.107743</td>\n",
       "      <td>2.414377</td>\n",
       "      <td>-0.973861</td>\n",
       "      <td>0.574503</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>-1.546406</td>\n",
       "      <td>-2.835276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 431 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               TransactionAmt  ProductCD     card1     card2     card3  \\\n",
       "TransactionID                                                            \n",
       "3379840             -0.437961  -2.273059 -1.595233  0.308872  2.414377   \n",
       "3415851             -0.365802  -0.863972  0.037220  1.408793 -0.202174   \n",
       "3269438              0.386127   0.545114 -1.478316  0.019750 -0.202174   \n",
       "3554694             -0.486700  -2.273059 -0.421679 -0.967037  2.414377   \n",
       "2994660             -0.468551   0.545114  0.170213  0.013464 -0.202174   \n",
       "...                       ...        ...       ...       ...       ...   \n",
       "2998035              0.151149   0.545114  0.674417  1.220235 -0.202174   \n",
       "3158790             -0.455520   0.545114 -0.912731  1.408793 -0.202174   \n",
       "3278176             -0.327351   0.545114 -0.738329  1.188809 -0.202174   \n",
       "3516397             -0.465684  -2.273059 -0.916628  0.107743  2.414377   \n",
       "3385240             -0.381169  -2.273059 -0.916628  0.107743  2.414377   \n",
       "\n",
       "                  card4     card5     card6     addr1     addr2  ...  id_31  \\\n",
       "TransactionID                                                    ...          \n",
       "3379840        0.643344 -2.256241 -1.679215 -1.546406 -2.835276  ...    0.0   \n",
       "3415851        0.643344  0.661603 -1.679215  0.586847  0.356219  ...    0.0   \n",
       "3269438        0.643344  0.661603  0.578667 -1.325725  0.356219  ...    0.0   \n",
       "3554694        0.643344 -1.385243  0.578667 -1.546406 -2.835276  ...    0.0   \n",
       "2994660       -0.973861 -1.864292  0.578667 -0.712721  0.356219  ...    0.0   \n",
       "...                 ...       ...       ...       ...       ...  ...    ...   \n",
       "2998035        0.643344  0.661603 -1.679215 -1.350245  0.356219  ...    0.0   \n",
       "3158790        0.643344  0.661603 -1.679215 -0.516560  0.356219  ...    0.0   \n",
       "3278176        0.643344  0.661603  0.578667  1.494093  0.356219  ...    0.0   \n",
       "3516397       -0.973861  0.574503  0.578667 -1.546406 -2.835276  ...    0.0   \n",
       "3385240       -0.973861  0.574503  0.578667 -1.546406 -2.835276  ...    0.0   \n",
       "\n",
       "               id_32  id_33  id_34  id_35  id_36  id_37  id_38  DeviceType  \\\n",
       "TransactionID                                                                \n",
       "3379840          0.0    0.0    0.0    0.0    0.0    0.0    0.0         0.0   \n",
       "3415851          0.0    0.0    0.0    0.0    0.0    0.0    0.0         0.0   \n",
       "3269438          0.0    0.0    0.0    0.0    0.0    0.0    0.0         0.0   \n",
       "3554694          0.0    0.0    0.0    0.0    0.0    0.0    0.0         0.0   \n",
       "2994660          0.0    0.0    0.0    0.0    0.0    0.0    0.0         0.0   \n",
       "...              ...    ...    ...    ...    ...    ...    ...         ...   \n",
       "2998035          0.0    0.0    0.0    0.0    0.0    0.0    0.0         0.0   \n",
       "3158790          0.0    0.0    0.0    0.0    0.0    0.0    0.0         0.0   \n",
       "3278176          0.0    0.0    0.0    0.0    0.0    0.0    0.0         0.0   \n",
       "3516397          0.0    0.0    0.0    0.0    0.0    0.0    0.0         0.0   \n",
       "3385240          0.0    0.0    0.0    0.0    0.0    0.0    0.0         0.0   \n",
       "\n",
       "               DeviceInfo  \n",
       "TransactionID              \n",
       "3379840               0.0  \n",
       "3415851               0.0  \n",
       "3269438               0.0  \n",
       "3554694               0.0  \n",
       "2994660               0.0  \n",
       "...                   ...  \n",
       "2998035               0.0  \n",
       "3158790               0.0  \n",
       "3278176               0.0  \n",
       "3516397               0.0  \n",
       "3385240               0.0  \n",
       "\n",
       "[80000 rows x 431 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engeering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Forest to get features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD5CAYAAADbY2myAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAArH0lEQVR4nO3df5QfdX3v8ed7ly+yoLKgwRuWYLieNBZKSWAv0HLaU21t+FGbVasBq1iPp5TT0lsozW3o4RS8F685pgh66sGDLRWPVIKVrlG5N/UIPfZwDWUhgRAhNaKGbFKIhaViFrPZvO8fM5PMfndmvp/5/v7u9/U453t2d74z85357sy85/P+fObzMXdHREQkxECnN0BERHqHgoaIiART0BARkWAKGiIiEkxBQ0REgh3T6Q0o441vfKMvXbq005shItJTHnvssR+7+6JmrKungsbSpUuZmJjo9GaIiPQUM/tRs9al9JSIiART0BARkWAKGiIiEkxBQ0REgiloiIhIsJ5qPVWP8a2TbNi8k71T05w6PMTaVcsZWznS6c0SEelJCzpojG+d5Ib7tzM9MwvA5NQ0N9y/HUCBQ0SkDgs6PbVh884jASMxPTPLhs07O7RFIiK9bUEHjb1T06Wmi4hIsQUdNE4dHio1XUREii3ooLF21XKGKoNzpg1VBlm7anmHtkhEpLct6IrwpLJbradERJpjQQcNiAKHgoSISHMs6PSUiIg0l4KGiIgEU9AQEZFgChoiIhJMQUNERIIpaIiISDAFDRERCRYUNMzsYjPbaWa7zGxdxvtmZp+O33/SzM6Npx9nZv9qZk+Y2Q4z+2hqmZPN7Jtm9r3450nN2y0REWmFmkHDzAaBzwCXAGcCV5jZmVWzXQIsi19XAXfE038GvN3dzwFWABeb2YXxe+uAb7n7MuBb8d8iItLFQkoa5wO73P1Zdz8I3AusrppnNfAFj2wBhs1scfz3K/E8lfjlqWXujn+/GxhrYD9ERKQNQoLGCPBc6u898bSgecxs0My2AS8A33T3R+J53uTu+wDin6eU3noREWmrkKBhGdM8dB53n3X3FcBpwPlm9gtlNtDMrjKzCTOb2L9/f5lFRUSkyUKCxh5gServ04C9Zedx9yngn4GL40nPm9ligPjnC1kf7u53uvuou48uWrQoYHNFRKRVQoLGo8AyMzvDzI4FLgc2Vc2zCbgybkV1IfCyu+8zs0VmNgxgZkPAbwDPpJb5UPz7h4CvNrYrxca3TnLR+gc5Y903uGj9g4xvnWzlx4mILEg1u0Z390Nmdg2wGRgE7nL3HWZ2dfz+Z4EHgEuBXcAB4MPx4ouBu+MWWAPAfe7+9fi99cB9ZvYRYDfw3ubt1lzjWye54f7tR8YLn5ya5ob7twOo23QRkRLMvbp6onuNjo76xMRE6eUuWv8gkxnjgo8MD/Hwurc3Y9NERLqWmT3m7qPNWFdfPBG+NyNgFE0XEZFsfRE0Th0eKjVdRESy9UXQWLtqOUOVwTnThiqDrF21vENbJCLSmxb8GOFwtLJ7w+ad7J2a5tThIdauWq5KcBGRkvoiaEAUOBQkREQa0xfpKRERaQ4FDRERCaagISIiwRQ0REQkmIKGiIgEU9AQEZFgChoiIhJMQUNERIIpaIiISDAFDRERCaagISIiwRQ0REQkmIKGiIgEU9AQEZFgChoiIhJMQUNERIIpaIiISLCgoGFmF5vZTjPbZWbrMt43M/t0/P6TZnZuPH2JmT1kZk+b2Q4z+5PUMjeb2aSZbYtflzZvt0REpBVqDvdqZoPAZ4B3AHuAR81sk7t/NzXbJcCy+HUBcEf88xBwvbs/bmavAx4zs2+mlr3N3f+qebsjIiKtFFLSOB/Y5e7PuvtB4F5gddU8q4EveGQLMGxmi919n7s/DuDuPwGeBjRQt4hIjwoJGiPAc6m/9zD/wl9zHjNbCqwEHklNviZOZ91lZidlfbiZXWVmE2Y2sX///oDNFRGRVgkJGpYxzcvMY2avBb4CXOvu/xlPvgN4C7AC2AfcmvXh7n6nu4+6++iiRYsCNldERFolJGjsAZak/j4N2Bs6j5lViALGPe5+fzKDuz/v7rPufhj4HFEaTEREulhI0HgUWGZmZ5jZscDlwKaqeTYBV8atqC4EXnb3fWZmwN8CT7v7J9MLmNni1J/vAp6qey9ERKQtaraecvdDZnYNsBkYBO5y9x1mdnX8/meBB4BLgV3AAeDD8eIXAR8EtpvZtnjaX7j7A8AnzGwFURrrh8AfNGmfRESkRcy9unqie42OjvrExESnN0NEpKeY2WPuPtqMdemJcBERCaagISIiwRQ0REQkmIKGiIgEU9AQEZFgChoiIhJMQUNERIIpaIiISDAFDRERCaagISIiwWr2PbVQjG+dZMPmneydmubU4SHWrlrO2EqNByUiUkZfBI3xrZPccP92pmdmAZicmuaG+7cDKHCIiJTQF+mpDZt3HgkYiemZWTZs3tmhLRIR6U19UdLYOzVdarqIlKP0b//oi5LGqcNDpaaLSLgk/Ts5NY1zNP07vnWy05smLdAXQWPtquUMVQbnTBuqDLJ21fIObZHIwqH0b3/pi/RUUkxW8Vmk+ZT+7S99ETQgChwKEiLNd+rwEJMZAULp34WpL9JTItI6Sv/2l74paYhIayj9218UNESkYUr/9o+g9JSZXWxmO81sl5mty3jfzOzT8ftPmtm58fQlZvaQmT1tZjvM7E9Sy5xsZt80s+/FP09q3m6JiEgr1AwaZjYIfAa4BDgTuMLMzqya7RJgWfy6Crgjnn4IuN7dfx64EPij1LLrgG+5+zLgW/HfIiLSxUJKGucDu9z9WXc/CNwLrK6aZzXwBY9sAYbNbLG773P3xwHc/SfA08BIapm749/vBsYa2xUREWm1kKAxAjyX+nsPRy/8wfOY2VJgJfBIPOlN7r4PIP55StaHm9lVZjZhZhP79+8P2FwREWmVkKBhGdO8zDxm9lrgK8C17v6f4ZsH7n6nu4+6++iiRYvKLCoiIk0WEjT2AEtSf58G7A2dx8wqRAHjHne/PzXP82a2OJ5nMfBCuU0XEZF2CwkajwLLzOwMMzsWuBzYVDXPJuDKuBXVhcDL7r7PzAz4W+Bpd/9kxjIfin//EPDVuvdCRETaouZzGu5+yMyuATYDg8Bd7r7DzK6O3/8s8ABwKbALOAB8OF78IuCDwHYz2xZP+wt3fwBYD9xnZh8BdgPvbdpeiYhIS5h7dfVE9xodHfWJiYlOb4aISE8xs8fcfbQZ61LfUyIiEkxBQ0REgiloiIhIMAUNEREJpqAhIiLBFDRERCSYgoaIiART0BARkWAKGiIiEqxvh3sd3zqpMY2lp+iYlW7Ql0FjfOskN9y/nemZWQAmp6a54f7tADoJpSvpmJVu0ZfpqQ2bdx45+RLTM7Ns2LyzQ1skUkzHrHSLvgwae6emS00X6TQds9It+jJonDo8VGq6SKfpmJVu0ZdBY+2q5QxVBudMG6oMsnbV8g5tkUgxHbPSLfqyIjypOFRLFOkVOmalW2gQJhGRBU6DMImISEcoaIiISDAFDRERCaagISIiwRQ0REQkWFDQMLOLzWynme0ys3UZ75uZfTp+/0kzOzf13l1m9oKZPVW1zM1mNmlm2+LXpY3vjoiItFLNoGFmg8BngEuAM4ErzOzMqtkuAZbFr6uAO1LvfR64OGf1t7n7ivj1QMltFxGRNgt5uO98YJe7PwtgZvcCq4HvpuZZDXzBo4c+tpjZsJktdvd97v5tM1va7A3vBHVNLSL9LiQ9NQI8l/p7Tzyt7DxZronTWXeZ2UlZM5jZVWY2YWYT+/fvD1hlayRdU09OTeMc7Zp6fOtkx7ZJRKTdQoKGZUyrfow8ZJ5qdwBvAVYA+4Bbs2Zy9zvdfdTdRxctWlRjla2jrqlFRMKCxh5gServ04C9dcwzh7s/7+6z7n4Y+BxRGqxrqWtqEZGwoPEosMzMzjCzY4HLgU1V82wCroxbUV0IvOzu+4pWamaLU3++C3gqb95uoK6ppZPGt05y0foHOWPdN7ho/YNKi0rH1Awa7n4IuAbYDDwN3OfuO8zsajO7Op7tAeBZYBdRqeEPk+XN7EvAd4DlZrbHzD4Sv/UJM9tuZk8CbwOua9ZOtYK6ppZOUX2adBP1cluCWk9JJ1y0/kEmM9KgI8NDPLzu7R3YIuk1zezlti/H06jX2MoRBQlpO9WnSTdRNyIiXU71adJNFDQCqSJSOkX1adJNlJ4KkFREJs9pJBWRgNJV0nIa6lW6iYJGrKiSu+jBPp240g6qT5NuoaBB7ZKEKiJFRCKq06B2FyGqiBQRiShoULtJoyoiRUQiSk8RlRiyHp5KShKqiBSpTQ+/9gcFDaKSRLpOA+aXJFQRKZJPLQz7R98FjVqtpHSXJFKeWhj2j74KGrXuhnRwi9RHLQz7R19VhGsgJZHWUAvD/tFXQaPRuyF1JSKSTS0M+0dfpadqtZIqooo+kXyqF+wffRU0QlpJ5VFFn0gx1Qv2h74KGo3cDS2Uij61pZd66LiRRF8FDaj/bqiR1Fa3UIpN6qHjRtL6qiI8T0gF90Ko6FPrMamHjhtJ67uSRrXQu6iFUNG3UFJs0j7jWyczS9ig46Zf9X3QKFPB3esVfQshxSbtk9xQ5dFx05+C0lNmdrGZ7TSzXWa2LuN9M7NPx+8/aWbnpt67y8xeMLOnqpY52cy+aWbfi3+e1PjulNdPd98LIcUm7ZN1Q5XQcdO/agYNMxsEPgNcApwJXGFmZ1bNdgmwLH5dBdyReu/zwMUZq14HfMvdlwHfiv9uu356knVs5Qgff/fZjAwPYcDI8BAff/fZPV16ktYpunHScdO/QtJT5wO73P1ZADO7F1gNfDc1z2rgC+7uwBYzGzazxe6+z92/bWZLM9a7Gvi1+Pe7gX8G/ryuvWhAI89u9KJeT7FJ++SlM0eGh3QM9bGQ9NQI8Fzq7z3xtLLzVHuTu+8DiH+ekjWTmV1lZhNmNrF///6AzS1Hd98i2dauWk5l0OZMqwzagr2hkjAhJQ3LmOZ1zFMXd78TuBNgdHS0KeusprtvkRzVZ1xLzkDpJSEljT3AktTfpwF765in2vNmthgg/vlCwLaISJts2LyTmcNzo8TMYdfzGX0uJGg8CiwzszPM7FjgcmBT1TybgCvjVlQXAi8nqacCm4APxb9/CPhqie2WOqiXXimjn1oWSriaQcPdDwHXAJuBp4H73H2HmV1tZlfHsz0APAvsAj4H/GGyvJl9CfgOsNzM9pjZR+K31gPvMLPvAe+I/5YWSdrcT05N4xx9iFGBQ/L0U8tCCWdRg6feMDo66hMTE53ejJ500foHc1vCPLzu7R3YIul21b0lQNSyUA1Feo+ZPebuo81YV18/Ed5PPXcq1SBlLYSuc6T5+jZoZPU5tfbLT/DRr+1g6sBM6ROk2wOQuhCReqhloVTr215us7pImDnsvHRgpnTOvxfqC9SFiIg0Q98GjZC0TGj3z73QdbQeYhSRZujb9FReuqba5NQ0b7nhAWbdGclJO/VKfUE/pRq6PV0orXXj+Ha+9MhzzLozaMYVFyzhlrGzO71ZC0LfljSy0jV5ZuMWZnlpJzVN7C69kC6UfI0+T3Tj+Ha+uGX3kfN21p0vbtnNjeP53bxLuL4NGtXpmuGhyrx+drJkpZ1UX9BdeiFdKNmaEfC/9MhzpaZLOX2bnoL56ZokpVErbZWkndIpkBOHKhxXGair5ZU0V6+kC2W+MoOi5ZnNefYsb7qU09dBo1oSRPIehEucOjw0r8nu1PQMQ5VBbluzQsGiw9S8uHc1I+APmmUGCCN6yFX1XI3p2/RUkaL6jiTtpBRI91K6sHc1o37wiguWZE4fGDDVczWBgkaGsZUjvOe8kXn9vRvwnvOi0ohSIN1LzYt7VzMC/i1jZ/OBC09n0KIz2OLXbFWPvdMzs1x/3xMKHCUpPZXjoWf2Zw4l8NAz0UBQSoF0t15qXqzmwUc1q+uSW8bO5paxszP7z0qbdeeG+7fP+Wwppg4Lc5yx7huZ480Y8IP1l2UejJUB47XHHaPKcAmWd1E76fgKN73zLB0/DapVP5lY6B13NrPDQqWnctTKrWY12cWY0w3JdRu3sVRjV0iBrLoxiI4j5dwbF5ouVlo5nIJGjpDc6tjKER5e93Z+sP4yTnjNMczMzi2bJH/1e6WbBn/KV3QXrIYVjQtNFyutHE5BI0fZytRadyr9egHQ09n5xrdOzmtsUU13wI0J6flBLevKUUV4gTKVqSF9WfXjBaAZD2stVBs278ysN0vTHXBjsirW3/bWRTz0zH41PKiTgkaTrF21vLCVBvTnBUBNk/PV+g50B9wcvdSSrhf0ZdBotInj+NZJbt60g6npGeBoS5ePv/vsI92QGMy5izSi1MxF6x/sqzsbNU3OV1Q6zetRWeqnps3N0XdBI2vEvjLttMe3TrL2y08wk3pQ6KUDM1y7cRsQney3r1kBkBlAyn5er8sqgekOOpL33fTzg4iturA3et7LUX33nEZeu+1BMw67Zx6o6QMZg1pfWfrEz/u8hd4uPE13ePn03RyV9cxKs4Jov5+HzXxOI6ikYWYXA58CBoG/cff1Ve9b/P6lwAHg99z98aJlzexm4PeB/fFq/sLdH2h0h2rJyyNXj5kB0R3IvAM5IMamK3qV01dOuUjed9OPwaSVjSby0oD9dB42S80mt2Y2CHwGuAQ4E7jCzM6smu0SYFn8ugq4I3DZ29x9RfxqecCAsFx6unls3sNXtSQHowZokrL6tZlyq26wipo26zwsL+Q5jfOBXe7+rLsfBO4FVlfNsxr4gke2AMNmtjhw2bYKHbEvOVDrPWCTg/Ftb12U+X7e9FbQw3W9pd09KHfL8dGqG6yips3tPA8XipD01AiQHvJqD3BBwDwjActeY2ZXAhPA9e7+UuB216263fZATt/7yYEaOpZ4WrqiN+ngsFre9GaqbuUF/VEB2MrK1HakjNqZ0gypIG7Xfreq0UTR9/aVxyYZffPJC/ZcaIWQkkZWya76Kps3T9GydwBvAVYA+4BbMz/c7CozmzCzif37m3OhTXf/cev7zinsLiSkZDJgUbPbrCfHO1WnkVwM0gEjsZCfTs9K7TSjD7B2pozamdL86Nd2FJZq2rnfrejSfnzrJAOW/9z99MwsN2/aUff6+1FISWMPkB7V5DRgb+A8x+Yt6+7PJxPN7HPA17M+3N3vBO6EqPVUwPaW9ppjBo6cONW9i1aXTE4cqnDw0CwHZg5nzl+tU88p1KqLCQ1avVYhm7XfzWju3M4n29vVTHl86yQvHZh/UwFHj492P9HfzEYTN45v554tu2u2XZmanmF862RXH9fdJCRoPAosM7MzgEngcuD9VfNsIko13UuUfnrZ3feZ2f68Zc1ssbvvi5d/F/BUw3tTUlYTv1fjYJCep5GLZqeeU6gVFEKCVtm27d0QYEL7ACu7Xe0sMTZrTIlaikqbyfHRq63/xrdOBgWMhLq1CVczaLj7ITO7BthM1Gz2LnffYWZXx+9/FniAqLntLqImtx8uWjZe9SfMbAXRjeAPgT9o4n7lSl/Ysuoz0heVZjwQ1K4LQLWiupjQoFXmLrPWd9WugNKsPsCqt3f4+ErmXXmrSozJHXeyHddt3MaGzTub+r0VfQ/J8dGrT/SH9OuV1u1BsJsEPacRN4d9oGraZ1O/O/BHocvG0z9YakuboPrCllUBDs0vmnfiOYW8vrDy0mlZF/Uyd5m1Wvy062ncZvQBlhUAKwNGZdDmdH/f6hJjq59izgsIw0OVI+vP+j6N7m91VDYIdHsQ7CZ91TV66DMXpw4PMb51sqcfCMqqVLx9zQq2/uVv5pYSqis7h4+vZK476wQrCjDtbEKa3u88tS54Wds7c9g54dhj2jrueN731qyK27wxY27+7bOO/D22coT3nDcyp0WLE7U6amZleDOb/daq/K4Mzn1P3dqU01d9T4Vc7Icqg7ztrYuO3NFlybpopu/UTxyqYEbHh30NLeHkXZxec8wAQ5XBoPqYvLvWAbO2B99kv/O6jrjnkd2FzSzztuvl6Rm23fSbTd1WyK8LytuOZlTcJp85PTPLYJymzesk8aFn9s9L9RSlKcueB2Wa/U5OTRdub7KurCyCAb974emMvvnkjte99bK+Chp5F7bqfqeKSiRZF83qg77XnosoukjetmZF0Am2dtXyeR05Qn4KEGoH30ZP6Lxg5Q5r/+EJIPt/0s48ftYF87qN25j40YuF9TONVNxmpWmTlFPWOkPTlPWeB0Ulqqy6xbwuf/LWlRg+vnLkZqFbz8Ve0Ffpqbzi+K3vO4cfrL+Mh9e9vfAOD8hMSdRKeyUnQCPF71Y+tVv0XED6mZbk+8lVaxi6lKLg24xnAmqNijcz67lpnpChfpslr4nwPVt2F6bRGimlFX1m1ncd+txIyHmQlZKsVaIqWm/1Oou+F4273hx9VdIIacmU5EOz7pBH4ototZATeGp65sidVz3dsbeyQrQZzYI3bN45b4z0POm0QpnWbGWEtJ7JS/O0s8Vb3rHjRGmhkwJbbVWX0IpGpyv6zKzvOvT4CDkPsuapVaKqtd70+7Vaz1W3jlSaqry+ChpQnOcvyocWXUTr6WqkzMWw1Q9Y5V0kIepSOuSkCt3/dFfUZVuzlRG6TN532K4URtGxs3dqmtvWrKh5wc66qfjilt1H3q++yaj1mdVCg2jIeXDi0PzGFWtXLT8yHk21dB1GnnQADWk9t3dqWuNrNKCv0lO15BWDB80KW8qEdoJYLfTCVs8DVmXTWdVpKCA4VVQrFZQwmHOxK9OarazQZTrdEm7tquWFPbCGdK0R8j2m0zi1PjNLSJpy7arlVAaKj4SfHjw07xgaWznCSTkt9aC4XgzgQGqdIa3nTh0eanunkAuJgkZK3gXksHvh3Uf1iT08VJnTF1XeCZF3glZf8Ms0fU2Wb7RuoMxJFZIKSlqupL/H0NZs9dQlhAbyTrfPH1s5wu9eePq8i3h6eGCg8IIdWspLvu+8z2y03mZs5QivPa44eTEz65nH0E3vPKuuGy+YX1eRBLjb16zIrZvq1Sfdu0HfpaeKNNJqpmgwnbwK1wMHD3Hj+PY5uee3vXURX3lssqEHy0LSWbXyuXknT9Y450UXLYPS6Yz08LjHVY7e15TJQVenVI6rDDBd1UVMt7TPv2Xs7CPNQGsND5z1HdRK3yQcjvzv0p9Zb04/a1umcvqySquVAiub6oXsdG1RWi3vczp9E9EL+m641yLNHm4ya321pC8YacNDFU54zTFBJ/gZ676RuQ4DfrD+ssL9hLATNz3/dRu3ZX5e0VCaWd22A1F6w5gXIN9z3sicYJrehlr/m6z9TUo+t4ydXbhsuxUNS5pXIV12kLBGj+ms4AbRd3r8sYP89GDx9tQaWjnveArxw/WXBc3XyqFlu1Hbh3vtF8nBkr6Ype90y6pn1L+8k2VqeoaXp8MeFqxVYsoridxw/5O8OnM46IRNp6ryAtTaVcsz70aBzGA6YMx7ziP5rC898lzdLavympi2akyTRlrl1PNkfV5JI+8GpN5GFNUX2up1O/DTg7PzSsXVaj1nUW/AsHgbQ/arU33CLQR9ETTynibNapYI8LNDR9MYSb4UyreqaHZ+NF0/UbQ9tZpI5m1XdfqmlqLSiAPXbtyWmWqJUkXzg2lGvDiikZZVZVJtjWq0VU5RwC8a3766xJFVYkur59gMvQk6ZsA4NOvzLv4DNv9/PD0zy/X3HX3QspFzJq/JcBY1t63fgq8IT1cKw9y7nC9u2T2vsrjWoDRZ689rpdSq/GhW/0Pp7diweSfnnn4ig3H/O4NmvOe8o3Uu7czbZnU/kTeGQ5HBnL6EQvalaJ5mDyrUaKucogcL8xpEGPCe80bmtLB67XHHFN7t562rSOgFfTqntJp3UzDrfuR/0OixGdqDcT+Owd4sC75OIy9HXFZSH5BWKy9aT51GGR+48HQeemZ/Zn45S9LDLWSnh/IMD1X42aHDLduPWiqDxpr/tiSoTqNMOiyt+vmRsneh6dJslqzjp2gd1f0rAZndtCQGzbj1fecc2c68eq3E8FBlTj9aIfvcrHMpj1nUxUvIsZynqL4kkbcf1d/JQtLMOo0FX9JoVooo6w6o1l1lSJvxRiQlJQg7yV46MHOkX6PQ7TLg5t8+a15Pp+10wrHHcMvY2fOaNR9XGeC6jduOlPDy7iAh6v5lOOPBskRynNRzF1pdms2StFzKW09WiTjpPHPD5p1cu3FbbsBI5r/h/u3cOL6di9Y/WPN4eDnVACF0n+t9HilhULh8cv/ayG3srHvN/1utbkukmEoaVbLuqvNaVRTdzRnM6eUzr2uSWhq56ypy0vGVoO36QNwr6PX3PVHX9jdD9V16XgnvuMpAZuoruYMsOhaSkkat1ktZd+Nlj7ETjh3kY++aezzlraPs/7/M/Ol9Cr3zzmv1Fur2NSvaeixlteALOQ4WGpU0Sihzd5SMJRA6uH1R/tWJ7lxeOjCDU/up1qL1tELIdiUBI69rlWYYHqrUfIr4xKHKnHqjvHqnvLqS5A6yqNSZdA5YVGl+3cZtc+7Gr9u4jRvHt5cuzf704Cxr/+GJOXe1Rf1BlVFm/uRuPO8CmnXnPbZyhIKhKgoZUeOIdt58ZH2vRc/mtDL9tlAs+KBRnSJKKlRHhof4wIWnZwaH0J5dQ7pN6FXDQxVuGTu7rmbDoYYqg/zWOYs5VOMiMjU9M+diXU9F+obNOwuDfNL8tqiCOKuJ6Re37K7rIlrdy26rGyfkpSJr/W+rK/DHt07W/P6Th1GrdaKcmvW9FnVbkjTbhdb2LN3L+qLJbUs7n1uAMaMyaEdGb2tltwrTM7NzOtZr1PBQJTdtknT+V9Qx3o3j23nl1UOlP7eoqXCRqekZfvdz3+Ge3/+loI720or2NWveok4Bi1T//2u1AhuOU7IvHZgJflK9lfJKFTe986zMhwgduO6+qN6vumeGazdu46Nf25E5XHI/WfAljVYq0x14YnioUlgh2xXcuf6+J1haowVON0lSi0X9fNXqGO+LW3YXVja3wsPff5GlcTPppNlskaHKILevWTFnSNZa/vPVmSODTpWVvlMvGgIZonTmzw4dPlISSQZ3KmvAKPw/NcPYypHcY9s9OhayAvhLB2a4duM2Vv7Pf+rbkoeCRgPquQv/rXMWs+2m3+T2NSu6NnjMHK6/DgaoO+fdiKTV2mW/uLhwAKWb3nlWVxYOJ6em+cpjk4U90EL0PAZEd8OhDnv+Q34h27V03TdY8dF/qhl4si609XzqYW+sA8O0opJRI60a+3lAJwWNBtSTh05y52MrR44Ej2acHN3EPbtpZaurf5ILb/WDbumGDEV3mJ2WBL6i4+rrT+xj7ZefoN1Zn6npmboDTz2q6yLrPXSKbuwa7ayyX7tSD6rTMLOLgU8Bg8DfuPv6qvctfv9S4ADwe+7+eNGyZnYysBFYCvwQeJ+7v9T4LtWv7ENdZfPQcHQAmPTnvOe8kSMP6S0Eec1TQ3LqSUeCf79lN+U6NYkk9SQDlt8h4Ugdg2a1y+TUdGEJtN6mrr0m6UMqr1fmt711UVB9WNagT4mxlSN89Gs76mpYkUhKYu2SPKDbyTqVms9pmNkg8G/AO4A9wKPAFe7+3dQ8lwJ/TBQ0LgA+5e4XFC1rZp8AXnT39Wa2DjjJ3f+8aFta2cttvb1e1hqutFrRcyBQ7kntMtK95Nb7zEio29esmPedhfRemu559r/e8I26K5jTPpAROMa3TtZVKSzl1fucUcjzEiHPx1QGjQ2/c07uOTy+dZI/3bitrhuUTqm1T1na/ZzG+cAud3/W3Q8C9wKrq+ZZDXzBI1uAYTNbXGPZ1cDd8e93A2ON7Upj6u0zKN0899b3nVOYahqqDGI2v5ljutfRZjxBnjW4zs2/fVbwdjb62VkHc63eS0eGh7htzYojF/hm1Ud/6ZHn5k2rVSHerYYqg4XbPVQZqPv/Wm/6pyjlODI8VHcqMKS+MOQZrLxBnxJjK0c4sceOhVr71GohQWMESJ95e+JpIfMULfsmd98HEP88JevDzewqM5sws4n9+1vTlTXUN6RqtVoj+H383WfnDlKTHlUtGXWs3hPZ48/Lezgx2c6sNMhQZZBlp5xQ5ydHJYUsRd/jDzOeh8nroLCsvBJV0gdXr0j+jze986zMZ4Mqg8bH3/2LpW46ktWUubinj+fb16zgk+/LHh3v9jUreHjd22tuSyMdUVafb3lqncMhA0d1m06OMBhSp5H1/6g+xvLmCVm2kLvfCdwJUXqqzLJlNDJqX1qtZ0JCRwwbWznCxI9e5J4tu+d8YUkqq6hzvJCifbKdefU4ZbuLGDTjiguW5A5qlPf95l1UrrhgSVOe4ci7KDUjn13v9rx+6JhSn5v1/0z/b6rz3HmdZRYNPFUr1VNr0Kq8usCier+iwbVCK6nT51vePtQ6h/OOzW7WyREGQ4LGHmBJ6u/TgL2B8xxbsOzzZrbY3ffFqawXymx4s9Uag6ITn1NrSM6sXk8rg1Zqm/OCXPX0vCASOtpZ2e/3lrGz+cH+V3j4+y/OmV4ZMF57XPhF94oLluS+d9M7zyrsOTbL8ZUBZg57YUuik46vcObi183b9mR7kq5Zqi/ov/yWk3l898s1v6OQh1XLDjK0dtXy3O+iVuVr0fZUD+Na3Xvv2MqRhoedTe9DPedw0b53o7LneLOFVIQfQ1SZ/evAJFFl9vvdfUdqnsuAazhaEf5pdz+/aFkz2wD8R6oi/GR3/x9F29KO4V7bMTBLsz6n+kLejpYVjWx7I12OZy1TVBoaMHj/BbWHcy36DotKYUUXwcSN49uPjDhYXRKrte5ODA7UieOp2er9/rKOpZOOr3DZLy6eM1Db0jcM8f++/2LHmm3X+z9pZkV4UC+3ceuo24mazd7l7h8zs6sB3P2zcZPbvwYuJmpy+2F3n8hbNp7+BuA+4HRgN/Bed59/a5bS6qAhIrIQtT1odAsFDRGR8tQ1uoiIdISChoiIBFPQEBGRYAoaIiISrKcqws1sP/CjOhd/Y/zzdcBPUj+zphW9t9DXoe3uvXX06nb3877X85kAP6Y+b3b3RXUuO0dPlTTcfZG7j9bzIvqyfwwcV/Uza1rRewt9Hdru3ltHr253P+97PZ/543qvf80KGNBjQUNERDpLQUNERIIFDcK0QNwZ//wV4F9SP7OmFb230Neh7e69dfTqdvfzvtfzmV2hpyrCRUSks5SeEhGRYAoaIiISzt2b9gLeAGyLX/9O1B168vexNZadjed7CvgycHwD2/HPwGjq7/XAd4nG/XgJWAP8A/BfgP9DNDCUXnrppVezXx8LuF6NEg0nMef3gOX+keiauQt4GXgF2An8csEyi4BHgK3Ar9R1fW1m0KjauJuBP6uadkzqdwemgVeJBmZ6JfXePcCfVi072EDQuJ3oAZlHgCeB1xANDvUycIgoYFX/s2eAw008eJq1rmZu00LYDr306ufXoYxp1xRcGy8H7m7k2t6yinAzu5ko8v0C8CKwEngc2Eh0Ef8l4DvAh4nu9t8MfBU4HjiXqJRyHXBT/N6pRBH1p/E8JxK1/jqFaKyOMpzsoWhFRBK1rhOH4/fLXkvS600uwMnfh6ldbVA9zyHgP4iyKEuIboIHgU8B1wLfBzYDPw/8BtF1cy+wHBgDPkl0PX0FuMPdbyr68HbVafwc8Bvufj3wDPCr8fS/BP43UfAwYAXwfqISwelERakLgYNEw8H+XDzPPwJ/DixmbsDYQRRUEodytqc1kVJEFpJawWAgYJ5a680KOk50zau+Th0Gfhb/TOabjZcfAE4mupY6cALR4HZPA/8XOI8ooPwx8Pl4mbcSBZZvAq8nqhq41MyS63Omdj2n8WV3n41/PxG4O/79NqBC1L9K8t6DRO2SK0R1DjuISivfB54jepz+nURRM3GYKED8PHMDYfX+5d05ZE1PonUzqYQjIkWS61fWtWKAKLWeMKJrlBPVJw8AFwFTwBBwBlGA2E9UwvgqUdr9VeAh4L3xe78KTBAFndcBy4Bv19rAVkvf/f8vog2GaOOWE130DwJfcvcV7v7HREFgkKjvlUNEpYxfBn6LKF11SbyOQ/Gy6aifBKhEEpmt6ic5f0PzA0be54iIVEsHh6T+MHEw/ulEHbi+mprvz4DXxu+9D/h7ouvhAPkZlo+7+wrgo8DfufvfFm1YJ5rcnkhUXwFRq6bdwA/Jv0gPEqW0rgFuBabc/WSOBoZjUi+IvrjqdVXvZ0h6Kin6NUs7UmJKu4ksDOlrT7rUkb6+GXASUaligCh4vI6oBdVrgEfd/cXUelYTZXCOA34NuI+o9++rzOz1wBXAdjM7pWjDOtGNyCc4mp5Kilb/naiSPCuIvQKcQ5TK+j7wpJntiqe/Pp4n2Y/QSqmk5FEUNJOiX7O0o5ShkozIwjBIlEUZYO51Kv27EwWBdMX4S0SNhhz4u6p1/itR46JTgbXuvs3MrgP+iqjO+CdEdSHfjv/O1qomtwHNYr3q768BH8yZdw3RMxbT8Ws78BaitNdTqSa+jwK/E//9U6KKnWVEra6m43UcJCrZLAV+AHydKOpuA/6aKDf4L0RB6d/jf8Ir8Tr/lCgHmDQTXpNeTzzP54nqYUarPuOXiEpYrxKVrl4mahqc/uzqfXgK+Gmn/kd66dUvr/h8T16dbkZb9nWYqGSyN75mXAP8GzCQ2r+bqXoEot6X+p4SEVkgzOxK4GNEz7l9OTX9ZqKb379q+DMUNEREJFTX9D1lZm8ws2fMbLrq9Vint01E+puZ/aOZTZnZrJl5G18/M7Pvm9mqTn8HCZU0REQkWNeUNEREpPspaIiISDAFDRERCaagISIiwf4/440+V4GFM4wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "RFR = RandomForestRegressor(max_samples=1000, max_features=100, max_depth=20)#, max_depth=10)\n",
    "RFR.fit(data.train_ x, data.train_y)\n",
    "features = data.train_x.columns\n",
    "importances = RFR.feature_importances_\n",
    "plt.scatter(features, importances)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_feature_count = 0\n",
    "for i in list(importances):\n",
    "    if i > 1e-4:\n",
    "        important_feature_count+=1\n",
    "important_feature_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Feature Selection on Low Importance Features by LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIF_list = []\n",
    "threshold = 1e-3\n",
    "for i in range(len(importances)):\n",
    "    if importances[i] < threshold:\n",
    "        LIF_list.append(features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FS(data,LIF_list)\n",
    "fs.feature_regressor()\n",
    "drop_features = []\n",
    "for i in range(len(fs.result)):\n",
    "    if fs.result[i] == 1:\n",
    "        drop_features.append(LIF_list[i])\n",
    "drop_features = ['C3', 'M1', 'M2', 'V1', 'V9', 'V11', 'V14', 'V15', 'V16', 'V22', 'V27', 'V28', 'V29', 'V31', 'V32', 'V41', 'V42', 'V46', 'V48', 'V49', 'V50', 'V51', 'V55', 'V58', 'V65', 'V68', 'V69', 'V70', 'V79', 'V84', 'V89', 'V90', 'V91', 'V93', 'V104', 'V105', 'V106', 'V107', 'V110', 'V111', 'V112', 'V114', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V138', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V152', 'V154', 'V155', 'V159', 'V160', 'V162', 'V166', 'V167', 'V169', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V179', 'V180', 'V181', 'V182', 'V185', 'V193', 'V196', 'V197', 'V202', 'V205', 'V206', 'V210', 'V215', 'V216', 'V217', 'V225', 'V227', 'V228', 'V235', 'V236', 'V237', 'V238', 'V240', 'V241', 'V248', 'V252', 'V253', 'V265', 'V267', 'V268', 'V269', 'V276', 'V286', 'V287', 'V303', 'V304', 'V305', 'V323', 'V325', 'V327', 'V328', 'V330', 'V331', 'V335', 'V336', 'V337', 'V339', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(LIF_list), len(drop_features)\n",
    "data.feature_dropping(drop_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>...</th>\n",
       "      <th>V320</th>\n",
       "      <th>V321</th>\n",
       "      <th>V322</th>\n",
       "      <th>V324</th>\n",
       "      <th>V326</th>\n",
       "      <th>V329</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V338</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3379840</th>\n",
       "      <td>-0.437961</td>\n",
       "      <td>-2.273059</td>\n",
       "      <td>-1.595233</td>\n",
       "      <td>0.308872</td>\n",
       "      <td>2.414377</td>\n",
       "      <td>0.643344</td>\n",
       "      <td>-2.256241</td>\n",
       "      <td>-1.679215</td>\n",
       "      <td>-1.546406</td>\n",
       "      <td>-2.835276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104191</td>\n",
       "      <td>-0.099449</td>\n",
       "      <td>-0.040188</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.076926</td>\n",
       "      <td>-0.053668</td>\n",
       "      <td>-0.044267</td>\n",
       "      <td>-0.045699</td>\n",
       "      <td>-0.02549</td>\n",
       "      <td>-0.056291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415851</th>\n",
       "      <td>-0.365802</td>\n",
       "      <td>-0.863972</td>\n",
       "      <td>0.037220</td>\n",
       "      <td>1.408793</td>\n",
       "      <td>-0.202174</td>\n",
       "      <td>0.643344</td>\n",
       "      <td>0.661603</td>\n",
       "      <td>-1.679215</td>\n",
       "      <td>0.586847</td>\n",
       "      <td>0.356219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104191</td>\n",
       "      <td>-0.099449</td>\n",
       "      <td>-0.040188</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.076926</td>\n",
       "      <td>-0.053668</td>\n",
       "      <td>-0.044267</td>\n",
       "      <td>-0.045699</td>\n",
       "      <td>-0.02549</td>\n",
       "      <td>-0.056291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269438</th>\n",
       "      <td>0.386127</td>\n",
       "      <td>0.545114</td>\n",
       "      <td>-1.478316</td>\n",
       "      <td>0.019750</td>\n",
       "      <td>-0.202174</td>\n",
       "      <td>0.643344</td>\n",
       "      <td>0.661603</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>-1.325725</td>\n",
       "      <td>0.356219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104191</td>\n",
       "      <td>-0.099449</td>\n",
       "      <td>-0.040188</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.076926</td>\n",
       "      <td>-0.053668</td>\n",
       "      <td>-0.044267</td>\n",
       "      <td>-0.045699</td>\n",
       "      <td>-0.02549</td>\n",
       "      <td>-0.056291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3554694</th>\n",
       "      <td>-0.486700</td>\n",
       "      <td>-2.273059</td>\n",
       "      <td>-0.421679</td>\n",
       "      <td>-0.967037</td>\n",
       "      <td>2.414377</td>\n",
       "      <td>0.643344</td>\n",
       "      <td>-1.385243</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>-1.546406</td>\n",
       "      <td>-2.835276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104191</td>\n",
       "      <td>-0.099449</td>\n",
       "      <td>-0.040188</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.076926</td>\n",
       "      <td>-0.053668</td>\n",
       "      <td>-0.044267</td>\n",
       "      <td>-0.045699</td>\n",
       "      <td>-0.02549</td>\n",
       "      <td>-0.056291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994660</th>\n",
       "      <td>-0.468551</td>\n",
       "      <td>0.545114</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.013464</td>\n",
       "      <td>-0.202174</td>\n",
       "      <td>-0.973861</td>\n",
       "      <td>-1.864292</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>-0.712721</td>\n",
       "      <td>0.356219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104191</td>\n",
       "      <td>-0.099449</td>\n",
       "      <td>-0.040188</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.076926</td>\n",
       "      <td>-0.053668</td>\n",
       "      <td>-0.044267</td>\n",
       "      <td>-0.045699</td>\n",
       "      <td>-0.02549</td>\n",
       "      <td>-0.056291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998035</th>\n",
       "      <td>0.151149</td>\n",
       "      <td>0.545114</td>\n",
       "      <td>0.674417</td>\n",
       "      <td>1.220235</td>\n",
       "      <td>-0.202174</td>\n",
       "      <td>0.643344</td>\n",
       "      <td>0.661603</td>\n",
       "      <td>-1.679215</td>\n",
       "      <td>-1.350245</td>\n",
       "      <td>0.356219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104191</td>\n",
       "      <td>-0.099449</td>\n",
       "      <td>-0.040188</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.076926</td>\n",
       "      <td>-0.053668</td>\n",
       "      <td>-0.044267</td>\n",
       "      <td>-0.045699</td>\n",
       "      <td>-0.02549</td>\n",
       "      <td>-0.056291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158790</th>\n",
       "      <td>-0.455520</td>\n",
       "      <td>0.545114</td>\n",
       "      <td>-0.912731</td>\n",
       "      <td>1.408793</td>\n",
       "      <td>-0.202174</td>\n",
       "      <td>0.643344</td>\n",
       "      <td>0.661603</td>\n",
       "      <td>-1.679215</td>\n",
       "      <td>-0.516560</td>\n",
       "      <td>0.356219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104191</td>\n",
       "      <td>-0.099449</td>\n",
       "      <td>-0.040188</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.076926</td>\n",
       "      <td>-0.053668</td>\n",
       "      <td>-0.044267</td>\n",
       "      <td>-0.045699</td>\n",
       "      <td>-0.02549</td>\n",
       "      <td>-0.056291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278176</th>\n",
       "      <td>-0.327351</td>\n",
       "      <td>0.545114</td>\n",
       "      <td>-0.738329</td>\n",
       "      <td>1.188809</td>\n",
       "      <td>-0.202174</td>\n",
       "      <td>0.643344</td>\n",
       "      <td>0.661603</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>1.494093</td>\n",
       "      <td>0.356219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104191</td>\n",
       "      <td>-0.099449</td>\n",
       "      <td>-0.040188</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.076926</td>\n",
       "      <td>-0.053668</td>\n",
       "      <td>-0.044267</td>\n",
       "      <td>-0.045699</td>\n",
       "      <td>-0.02549</td>\n",
       "      <td>-0.056291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516397</th>\n",
       "      <td>-0.465684</td>\n",
       "      <td>-2.273059</td>\n",
       "      <td>-0.916628</td>\n",
       "      <td>0.107743</td>\n",
       "      <td>2.414377</td>\n",
       "      <td>-0.973861</td>\n",
       "      <td>0.574503</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>-1.546406</td>\n",
       "      <td>-2.835276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104191</td>\n",
       "      <td>-0.099449</td>\n",
       "      <td>-0.040188</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.076926</td>\n",
       "      <td>-0.053668</td>\n",
       "      <td>-0.044267</td>\n",
       "      <td>-0.045699</td>\n",
       "      <td>-0.02549</td>\n",
       "      <td>-0.056291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385240</th>\n",
       "      <td>-0.381169</td>\n",
       "      <td>-2.273059</td>\n",
       "      <td>-0.916628</td>\n",
       "      <td>0.107743</td>\n",
       "      <td>2.414377</td>\n",
       "      <td>-0.973861</td>\n",
       "      <td>0.574503</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>-1.546406</td>\n",
       "      <td>-2.835276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104191</td>\n",
       "      <td>-0.099449</td>\n",
       "      <td>-0.040188</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.076926</td>\n",
       "      <td>-0.053668</td>\n",
       "      <td>-0.044267</td>\n",
       "      <td>-0.045699</td>\n",
       "      <td>-0.02549</td>\n",
       "      <td>-0.056291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               TransactionAmt  ProductCD     card1     card2     card3  \\\n",
       "TransactionID                                                            \n",
       "3379840             -0.437961  -2.273059 -1.595233  0.308872  2.414377   \n",
       "3415851             -0.365802  -0.863972  0.037220  1.408793 -0.202174   \n",
       "3269438              0.386127   0.545114 -1.478316  0.019750 -0.202174   \n",
       "3554694             -0.486700  -2.273059 -0.421679 -0.967037  2.414377   \n",
       "2994660             -0.468551   0.545114  0.170213  0.013464 -0.202174   \n",
       "...                       ...        ...       ...       ...       ...   \n",
       "2998035              0.151149   0.545114  0.674417  1.220235 -0.202174   \n",
       "3158790             -0.455520   0.545114 -0.912731  1.408793 -0.202174   \n",
       "3278176             -0.327351   0.545114 -0.738329  1.188809 -0.202174   \n",
       "3516397             -0.465684  -2.273059 -0.916628  0.107743  2.414377   \n",
       "3385240             -0.381169  -2.273059 -0.916628  0.107743  2.414377   \n",
       "\n",
       "                  card4     card5     card6     addr1     addr2  ...  \\\n",
       "TransactionID                                                    ...   \n",
       "3379840        0.643344 -2.256241 -1.679215 -1.546406 -2.835276  ...   \n",
       "3415851        0.643344  0.661603 -1.679215  0.586847  0.356219  ...   \n",
       "3269438        0.643344  0.661603  0.578667 -1.325725  0.356219  ...   \n",
       "3554694        0.643344 -1.385243  0.578667 -1.546406 -2.835276  ...   \n",
       "2994660       -0.973861 -1.864292  0.578667 -0.712721  0.356219  ...   \n",
       "...                 ...       ...       ...       ...       ...  ...   \n",
       "2998035        0.643344  0.661603 -1.679215 -1.350245  0.356219  ...   \n",
       "3158790        0.643344  0.661603 -1.679215 -0.516560  0.356219  ...   \n",
       "3278176        0.643344  0.661603  0.578667  1.494093  0.356219  ...   \n",
       "3516397       -0.973861  0.574503  0.578667 -1.546406 -2.835276  ...   \n",
       "3385240       -0.973861  0.574503  0.578667 -1.546406 -2.835276  ...   \n",
       "\n",
       "                   V320      V321      V322      V324      V326      V329  \\\n",
       "TransactionID                                                               \n",
       "3379840       -0.104191 -0.099449 -0.040188 -0.045024 -0.076926 -0.053668   \n",
       "3415851       -0.104191 -0.099449 -0.040188 -0.045024 -0.076926 -0.053668   \n",
       "3269438       -0.104191 -0.099449 -0.040188 -0.045024 -0.076926 -0.053668   \n",
       "3554694       -0.104191 -0.099449 -0.040188 -0.045024 -0.076926 -0.053668   \n",
       "2994660       -0.104191 -0.099449 -0.040188 -0.045024 -0.076926 -0.053668   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "2998035       -0.104191 -0.099449 -0.040188 -0.045024 -0.076926 -0.053668   \n",
       "3158790       -0.104191 -0.099449 -0.040188 -0.045024 -0.076926 -0.053668   \n",
       "3278176       -0.104191 -0.099449 -0.040188 -0.045024 -0.076926 -0.053668   \n",
       "3516397       -0.104191 -0.099449 -0.040188 -0.045024 -0.076926 -0.053668   \n",
       "3385240       -0.104191 -0.099449 -0.040188 -0.045024 -0.076926 -0.053668   \n",
       "\n",
       "                   V332      V333     V334      V338  \n",
       "TransactionID                                         \n",
       "3379840       -0.044267 -0.045699 -0.02549 -0.056291  \n",
       "3415851       -0.044267 -0.045699 -0.02549 -0.056291  \n",
       "3269438       -0.044267 -0.045699 -0.02549 -0.056291  \n",
       "3554694       -0.044267 -0.045699 -0.02549 -0.056291  \n",
       "2994660       -0.044267 -0.045699 -0.02549 -0.056291  \n",
       "...                 ...       ...      ...       ...  \n",
       "2998035       -0.044267 -0.045699 -0.02549 -0.056291  \n",
       "3158790       -0.044267 -0.045699 -0.02549 -0.056291  \n",
       "3278176       -0.044267 -0.045699 -0.02549 -0.056291  \n",
       "3516397       -0.044267 -0.045699 -0.02549 -0.056291  \n",
       "3385240       -0.044267 -0.045699 -0.02549 -0.056291  \n",
       "\n",
       "[80000 rows x 272 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下中为各个结构的神经网络的尝试，测试中发现差别不大，故采用第一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variational_estimator\n",
    "class BayesianNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.blinear = BayesianLinear(input_dim, input_dim)\n",
    "        self.blinear1 = BayesianLinear(input_dim, 400)\n",
    "        self.linear1 = nn.Linear(400, 250)\n",
    "        self.linear2 = nn.Linear(250, 50)\n",
    "        self.linear3 = nn.Linear(50, 15)\n",
    "        self.linear = BayesianLinear(15, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.blinear(x))\n",
    "        x = torch.relu(self.blinear1(x))\n",
    "        x = F.dropout(x, p=0.20)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        #x = F.relu(self.linear4(x))\n",
    "        #x = F.relu(self.linear5(x))\n",
    "        #x = F.relu(self.linear6(x))\n",
    "        x = torch.sigmoid(self.linear(x))\n",
    "        return x\n",
    "    \n",
    "    def store(self):\n",
    "        torch.save(self.state_dict(), 'best_model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variational_estimator\n",
    "class BayesianNN1(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.blinear = BayesianLinear(input_dim, input_dim)\n",
    "        self.linear1 = nn.Linear(input_dim, 400)\n",
    "        self.linear2 = nn.Linear(400, 50)\n",
    "        self.linear3 = nn.Linear(50, 15)\n",
    "        self.linear = BayesianLinear(15, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.blinear(x))\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.dropout(x, p=0.20)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = torch.sigmoid(self.linear(x))\n",
    "        return x\n",
    "    \n",
    "    def store(self):\n",
    "        torch.save(self.state_dict(), 'best_model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variational_estimator\n",
    "class BayesianNN2(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.blinear = BayesianLinear(input_dim, input_dim)\n",
    "        self.linear1 = nn.Linear(input_dim, 400)\n",
    "        self.linear2 = nn.Linear(400, 300)\n",
    "        self.linear3 = nn.Linear(300, 50)\n",
    "        self.linear4 = nn.Linear(50, 15)\n",
    "        self.linear = BayesianLinear(15, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.blinear(x))\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = F.relu(self.linear4(x))\n",
    "        x = torch.sigmoid(self.linear(x))\n",
    "        return x\n",
    "    \n",
    "    def store(self):\n",
    "        torch.save(self.state_dict(), 'best_model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variational_estimator\n",
    "class BayesianNN3(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.blinear = BayesianLinear(input_dim, input_dim)\n",
    "        self.linear1 = nn.Linear(input_dim, 400)\n",
    "        self.linear2 = nn.Linear(400, 300)\n",
    "        self.linear3 = nn.Linear(300, 150)\n",
    "        self.linear4 = nn.Linear(150, 50)\n",
    "        self.linear4 = nn.Linear(50, 15)\n",
    "        self.linear = BayesianLinear(15, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.blinear(x))\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = F.relu(self.linear4(x))\n",
    "        x = F.relu(self.linear5(x))\n",
    "        x = torch.sigmoid(self.linear(x))\n",
    "        return x\n",
    "    \n",
    "    def store(self):\n",
    "        torch.save(self.state_dict(), 'best_model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_split(x, y, train_size=0.8):\n",
    "    train_x, vali_x, train_y, vali_y = train_test_split(x, y, train_size=train_size)\n",
    "    \n",
    "    train_x = torch.tensor(train_x.values).float()#.to('cuda:0')\n",
    "    train_y = torch.tensor(train_y.values.reshape(-1,1)).float()#.to('cuda:0')\n",
    "    valid_x = torch.tensor(vali_x.values).float().to('cuda:0')\n",
    "    valid_y = torch.tensor(vali_y.values.reshape(-1,1)).float()#.to('cuda:0')\n",
    "    \n",
    "    train = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "    valid = (valid_x, valid_y)\n",
    "    return train, valid\n",
    "\n",
    "train, valid = train_validate_split(data.train_x, data.train_y)\n",
    "tensor_data = (train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration: [100/33333], Loss:0.0862, Auc:0.8116\n",
      "#Iteration: [200/33333], Loss:0.0689, Auc:0.8171\n",
      "#Iteration: [300/33333], Loss:0.2292, Auc:0.8387\n",
      "#Iteration: [400/33333], Loss:0.1048, Auc:0.8350\n",
      "#Iteration: [500/33333], Loss:0.1532, Auc:0.8465\n",
      "#Iteration: [600/33333], Loss:0.1488, Auc:0.8395\n",
      "#Iteration: [700/33333], Loss:0.1272, Auc:0.8426\n",
      "#Iteration: [800/33333], Loss:0.1481, Auc:0.8518\n",
      "#Iteration: [900/33333], Loss:0.1012, Auc:0.8516\n",
      "#Iteration: [1000/33333], Loss:0.0840, Auc:0.8444\n",
      "#Iteration: [1100/33333], Loss:0.1397, Auc:0.8542\n",
      "#Iteration: [1200/33333], Loss:0.1020, Auc:0.8514\n",
      "#Iteration: [1300/33333], Loss:0.0891, Auc:0.8448\n",
      "#Iteration: [1400/33333], Loss:0.2466, Auc:0.8532\n",
      "#Iteration: [1500/33333], Loss:0.0618, Auc:0.8560\n",
      "#Iteration: [1600/33333], Loss:0.2613, Auc:0.8520\n",
      "#Iteration: [1700/33333], Loss:0.0650, Auc:0.8532\n",
      "#Iteration: [1800/33333], Loss:0.1989, Auc:0.8564\n",
      "#Iteration: [1900/33333], Loss:0.0852, Auc:0.8400\n",
      "#Iteration: [2000/33333], Loss:0.0758, Auc:0.8573\n",
      "#Iteration: [2100/33333], Loss:0.0729, Auc:0.8574\n",
      "#Iteration: [2200/33333], Loss:0.1023, Auc:0.8467\n",
      "#Iteration: [2300/33333], Loss:0.1916, Auc:0.8560\n",
      "#Iteration: [2400/33333], Loss:0.0971, Auc:0.8507\n",
      "#Iteration: [2500/33333], Loss:0.2640, Auc:0.8596\n",
      "#Iteration: [2600/33333], Loss:0.0925, Auc:0.8547\n",
      "#Iteration: [2700/33333], Loss:0.1037, Auc:0.8537\n",
      "#Iteration: [2800/33333], Loss:0.2500, Auc:0.8481\n",
      "#Iteration: [2900/33333], Loss:0.1360, Auc:0.8495\n",
      "#Iteration: [3000/33333], Loss:0.1790, Auc:0.8401\n",
      "#Iteration: [3100/33333], Loss:0.0524, Auc:0.8474\n",
      "#Iteration: [3200/33333], Loss:0.0592, Auc:0.8511\n",
      "#Iteration: [3300/33333], Loss:0.0977, Auc:0.8585\n",
      "#Iteration: [3400/33333], Loss:0.1640, Auc:0.8542\n",
      "#Iteration: [3500/33333], Loss:0.1101, Auc:0.8496\n",
      "#Iteration: [3600/33333], Loss:0.0618, Auc:0.8555\n",
      "#Iteration: [3700/33333], Loss:0.0907, Auc:0.8544\n",
      "#Iteration: [3800/33333], Loss:0.0422, Auc:0.8584\n",
      "#Iteration: [3900/33333], Loss:0.1109, Auc:0.8458\n",
      "#Iteration: [4000/33333], Loss:0.2058, Auc:0.8401\n",
      "#Iteration: [4100/33333], Loss:0.2055, Auc:0.8510\n",
      "#Iteration: [4200/33333], Loss:0.0507, Auc:0.8508\n",
      "#Iteration: [4300/33333], Loss:0.0669, Auc:0.8569\n",
      "#Iteration: [4400/33333], Loss:0.0542, Auc:0.8508\n",
      "#Iteration: [4500/33333], Loss:0.0513, Auc:0.8504\n",
      "#Iteration: [4600/33333], Loss:0.0628, Auc:0.8590\n",
      "#Iteration: [4700/33333], Loss:0.0320, Auc:0.8583\n",
      "#Iteration: [4741/33333], Loss:0.1279, Auc:0.8509\n",
      "Early Stopped\n",
      "#Best score:0.8673\n"
     ]
    }
   ],
   "source": [
    "def model_training(data, module, loss_func=nn.BCELoss(), max_epochs=100, early_stop=1600, bs=120, lr=0.002, gpu=True):\n",
    "    if gpu:\n",
    "        module.cuda()\n",
    "    optimizer = optim.Adam(module.parameters(), lr=lr)\n",
    "    trainDL = utils.data.DataLoader(data[0], batch_size=bs, shuffle=True)\n",
    "    scores = dict()\n",
    "    ite = 0\n",
    "    max_ite = round(max_epochs*64000/bs)\n",
    "    scores = [0 for i in range(early_stop)]\n",
    "    best_ite_module = module\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(max_epochs):\n",
    "        for step, xy in enumerate(trainDL):\n",
    "            x, y = xy\n",
    "            #print(x,y)\n",
    "            x, y = x.to('cuda:0'), y.to('cuda:0')\n",
    "            ite+=1\n",
    "            prediction = module(x)\n",
    "            #print(prediction)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_func(prediction, y)\n",
    "            #module.sample_elbo(inputs=x,\n",
    "            #                   labels=y,\n",
    "            #                   criterion=loss_func,\n",
    "            #                   sample_nbr=3)\n",
    "            valid_loss = loss_func(module(data[1][0]), data[1][1].cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            score = roc_auc_score(data[1][1].detach().numpy().reshape([-1,]), module(data[1][0]).cpu().detach().numpy().reshape([-1,]))\n",
    "            scores.append(score)\n",
    "            losses.append(loss.item())\n",
    "            val_losses.append(valid_loss.item())\n",
    "            if loss.item() < 2e-4:\n",
    "                print('#Iteration: [{}/{}], Loss:{:.4f}, Auc:{:.4f}'.format(ite, max_ite, loss.item(), score))\n",
    "                return best_score, losses, val_losses\n",
    "            elif max(scores) == scores[-1]:\n",
    "                module.store()\n",
    "                best_score = scores[-1]\n",
    "            elif max(scores) == scores[0]:\n",
    "                print('#Iteration: [{}/{}], Loss:{:.4f}, Auc:{:.4f}'.format(ite, max_ite, loss.item(), score))\n",
    "                print('Early Stopped')\n",
    "                print('#Best score:{:.4f}'.format(best_score))\n",
    "                return best_score, losses, val_losses\n",
    "            \n",
    "            if ite%100 == 0:\n",
    "                print('#Iteration: [{}/{}], Loss:{:.4f}, Auc:{:.4f}'.format(ite, max_ite, loss.item(), score))\n",
    "            scores.pop(0)\n",
    "            \n",
    "    return best_score, losses, val_losses\n",
    "\n",
    "module1 = BayesianNN(len(data.train_x.columns))\n",
    "best_score1, losses1, val_losses1 = model_training(tensor_data, module1)\n",
    "#best_score\n",
    "#module2 = BayesianNN1(len(data.train_x.columns))\n",
    "#best_score2, losses2 = model_training(tensor_data, module2)\n",
    "#module3 = BayesianNN2(len(data.train_x.columns))\n",
    "#best_score3, losses3 = model_training(tensor_data, module3)\n",
    "#module4 = BayesianNN2(len(data.train_x.columns))\n",
    "#best_score4, losses4 = model_training(tensor_data, module4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4741, 4741)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max(map(len,[losses1,val_losses1]))\n",
    "for j in [losses1,val_losses1]:\n",
    "    for i in range(max_len):\n",
    "        i+=1\n",
    "        if len(j)<i:\n",
    "            j.append(0)\n",
    "len(losses1), len(val_losses1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(max_len), losses1, c=\"orange\")\n",
    "plt.plot(range(max_len), val_losses1, c=\"cornflowerblue\")\n",
    "#plt.plot(range(max_len), losses2, c=\"cornflowerblue\")\n",
    "#plt.plot(range(max_len), losses3, c=\"pink\")\n",
    "#plt.plot(range(max_len), losses4, c=\"yellow\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8621531002850971"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = module1\n",
    "model.load_state_dict(torch.load('best_model.txt'))\n",
    "model.eval()\n",
    "roc_auc_score(valid[1].detach().numpy().reshape([-1,]), module1(valid[0]).cpu().detach().numpy().reshape([-1,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = module1(torch.Tensor(data.target_x.values).cuda())\n",
    "result = pd.DataFrame(prediction.cpu().detach().numpy(),index=data.target_x.index, columns=[\"isFraud\"])\n",
    "result.to_csv(\"newsample_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
